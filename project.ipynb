{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **INITIALIZATION**"
      ],
      "metadata": {
        "id": "or_wugzpQdow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as nd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "from tabulate import tabulate\n",
        "from IPython.display import display, Image, Markdown\n",
        "from difflib import get_close_matches\n",
        "plt.ioff()\n",
        "\n",
        "# seaborn parameters\n",
        "sns.set(style=\"whitegrid\", context=\"paper\", rc={\"axes.titlesize\": 14, \"axes.labelsize\": 12,\n",
        "    \"xtick.labelsize\": 12, \"ytick.labelsize\": 12})\n",
        "\n",
        "# URL to get raw CSV data from GitHub\n",
        "url = \"https://raw.githubusercontent.com/ayushinto-space/Performance-Metrics-and-Sales-Analysis-Using-Python/main/Sales_Dataset_Uncleaned.csv\"\n",
        "df_unclean = pd.read_csv(url)\n",
        "df_unclean.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xl4F9pjvIoN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA CLEANING**"
      ],
      "metadata": {
        "id": "JOCdiVnVQ5gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data uniformity\n",
        "df_unclean.columns = df_unclean.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "df_unclean.drop_duplicates(inplace=True)\n",
        "\n",
        "num_cols = ['quantity', 'unit_price', 'discount', 'sales', 'profit']\n",
        "df_unclean['order_date'] = pd.to_datetime(df_unclean['order_date'], errors='coerce')\n",
        "df_unclean[num_cols] = df_unclean[num_cols].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# missing value handles\n",
        "# for numeric values replaced with median\n",
        "for col in num_cols:\n",
        "    df_unclean[col] = df_unclean[col].fillna(df_unclean[col].median())\n",
        "\n",
        "# for string values replaced with unknown\n",
        "cat_cols = ['customer_name','region','city','category','sub-category',\n",
        "            'product_name','payment_mode']\n",
        "for col in cat_cols:\n",
        "    df_unclean[col] = df_unclean[col].fillna('Unknown')\n",
        "\n",
        "# data uniformity\n",
        "df_unclean['profit_margin'] = (df_unclean['profit'] / df_unclean['sales'])*100\n",
        "df_unclean['category'] = df_unclean['category'].str.title()\n",
        "df_unclean['sub-category'] = df_unclean['sub-category'].str.title()\n",
        "df_unclean['city'] = df_unclean['city'].str.title()\n",
        "df_unclean['region'] = df_unclean['region'].str.title()\n",
        "df_unclean['payment_mode'] = df_unclean['payment_mode'].str.title()\n",
        "df_unclean['order_month_name'] = df_unclean['order_date'].dt.month_name()\n",
        "df_unclean['order_month_num'] = df_unclean['order_date'].dt.month\n",
        "\n",
        "\n",
        "# data outliners\n",
        "# clipping outliners to 99%ile of dataset\n",
        "q99 = df_unclean['quantity'].quantile(0.99)\n",
        "df_unclean['quantity'] = df_unclean['quantity'].clip(upper=q99)\n",
        "p99 = df_unclean['unit_price'].quantile(0.99)\n",
        "df_unclean['unit_price'] = df_unclean['unit_price'].clip(upper=p99)\n",
        "\n",
        "# save\n",
        "df_unclean.to_csv(\"Sales_Cleaned.csv\", index=False)\n",
        "files.download(\"Sales_Cleaned.csv\")\n",
        "\n",
        "print(df_unclean.info())\n",
        "print(df_unclean.isna().sum())\n",
        "df_unclean.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z8VpuCdRRlNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPLORATION FUNCTIONS**"
      ],
      "metadata": {
        "id": "2IGOor4aMG5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TIME-BASED FUNCTIONS**"
      ],
      "metadata": {
        "id": "uULA_My8MMpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sales by year\n",
        "def sales_by_year(df_clean):\n",
        "    df_copy = df_clean.copy()\n",
        "    df_copy[\"year\"] = df_copy[\"order_date\"].dt.year\n",
        "    return df_copy.groupby(\"year\")[\"sales\"].sum()\n",
        "\n",
        "# profit margin by year\n",
        "def profit_margin_by_year(df_clean):\n",
        "    df_copy = df_clean.copy()\n",
        "    df_copy[\"year\"] = df_copy[\"order_date\"].dt.year\n",
        "    yearly = df_copy.groupby(\"year\")[[\"sales\", \"profit\"]].sum()\n",
        "    yearly[\"profit_margin\"] = yearly[\"profit\"] / yearly[\"sales\"]\n",
        "    return yearly[\"profit_margin\"]\n",
        "\n",
        "# sales by month\n",
        "def sales_by_month(df_clean):\n",
        "    df_clean = df_clean.copy()\n",
        "    df_clean['month'] = df_clean['order_date'].dt.to_period('M')\n",
        "    monthly = df_clean.groupby('month')['profit'].sum()\n",
        "    return monthly"
      ],
      "metadata": {
        "id": "HQ3yiHxMMGRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **REGION-BASED FUNCTIONS**"
      ],
      "metadata": {
        "id": "AkCiE8bgq-KL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# top cities\n",
        "def top_cities(df, top = 10):\n",
        "    df_copy = df.copy()\n",
        "    city_data = df_copy.groupby('city')[['sales','profit']].sum()\n",
        "    city_data = city_data.sort_values('sales', ascending=False).head(top)\n",
        "    return city_data"
      ],
      "metadata": {
        "id": "JYuiaAyyq5r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPLORATION**"
      ],
      "metadata": {
        "id": "EZSkKIP0UqQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/ayushinto-space/Performance-Metrics-and-Sales-Analysis-Using-Python/main/Sales_Cleaned.csv\"\n",
        "df_clean = pd.read_csv(url)\n",
        "df_clean['order_date'] = pd.to_datetime(df_clean['order_date'])\n",
        "\n",
        "df_clean.head()\n",
        "\n",
        "# plot sales by year\n",
        "def plot_sales_by_year(df_clean):\n",
        "    yearly_sales = sales_by_year(df_clean)\n",
        "\n",
        "    plt.figure(figsize=(7, 4.5))\n",
        "    sns.barplot(x=yearly_sales.index, y=yearly_sales.values, palette=\"PuBuGn\", hue=None, legend=False)\n",
        "\n",
        "    plt.title(\"Total Sales by Year\", fontsize=14)\n",
        "    plt.xlabel(\"Year\", fontsize=12)\n",
        "    plt.ylabel(\"Sales\", fontsize=12)\n",
        "\n",
        "    plt.xticks(fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "\n",
        "    plt.ylim(1e7, 5e8)\n",
        "\n",
        "    sns.despine()\n",
        "    plt.tight_layout()\n",
        "    fig = plt.gcf()\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "    display(Markdown(\"\"\"**Conclusion:** From the graph it can be interpreted that year on year sales growth had increased sharply in the year 2024.\n",
        "    The sales performance for the year 2025 has slightly dipped when compared to the preivous financial year.\"\"\"))\n",
        "\n",
        "\n",
        "# plot profit margin by year\n",
        "def plot_profit_margin_by_year(df_clean):\n",
        "    yearly_margin = profit_margin_by_year(df_clean)\n",
        "    plt.figure(figsize=(7, 4.5))\n",
        "    sns.lineplot(x=yearly_margin.index, y=yearly_margin.values*100, marker='o', linewidth=2,\n",
        "        markersize=7, color=\"crimson\")\n",
        "\n",
        "    plt.title(\"Profit Margin by Year\", fontsize=14)\n",
        "    plt.xlabel(\"Year\", fontsize=12)\n",
        "    plt.ylabel(\"Profit Margin\", fontsize=12)\n",
        "\n",
        "    plt.xticks([2023, 2023.5, 2024, 2024.5, 2025])\n",
        "    plt.xticks(fontsize=12)\n",
        "    plt.yticks(fontsize=12)\n",
        "\n",
        "    sns.despine()\n",
        "    plt.tight_layout()\n",
        "    fig = plt.gcf()\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "    display(Markdown(\"\"\"**Conclusion:** Profit margin for the company has increased throughout the years and has reached 15.05% by the end of its\n",
        "    third financial year.\"\"\"))\n",
        "\n",
        "# plot sales by month\n",
        "def plot_sales_by_month(df_clean):\n",
        "    monthly = sales_by_month(df_clean)\n",
        "    plt.figure(figsize=(7,4.5))\n",
        "    plt.plot(monthly.index.astype(str), monthly.values)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.title(\"Monthly Sales Trend\")\n",
        "    plt.xlabel(\"Month\")\n",
        "    plt.ylabel(\"Total Sales\")\n",
        "    plt.tight_layout()\n",
        "    fig = plt.gcf()\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "    display(Markdown(\"\"\"**Conclusion:** On analyzing month on month total sales slight spikes and variations are observed during seasonal change and festical period.\"\"\"))\n",
        "\n",
        "# plot top cities\n",
        "def plot_top_cities(df, top =10):\n",
        "    city_data = top_cities(df, top)\n",
        "    plt.figure(figsize=(10,5))\n",
        "    sns.barplot(x=city_data.index, y=city_data['sales'], palette='coolwarm')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title(f\"Top {top} Cities by Sales\")\n",
        "    plt.xlabel(\"City\")\n",
        "    plt.ylabel(\"Sales\")\n",
        "    plt.tight_layout()\n",
        "    fig = plt.gcf()\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "    display(Markdown(\"\"\"**Conclusion:** The top 10 cities include mostly the urban cities. The company should provide better service\n",
        "    from cities where the revenue is maximum. Further, it should penetrate into the cities which its service are available but not not commonly used\"\"\"))\n",
        "\n",
        "# calling all plot functions\n",
        "plot_sales_by_year(df_clean,)\n",
        "plot_profit_margin_by_year(df_clean)\n",
        "plot_sales_by_month(df_clean)\n",
        "plot_top_cities(df_clean)"
      ],
      "metadata": {
        "id": "QPxCJCjyW4zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INTERACTIVE ENVIRONMENT**"
      ],
      "metadata": {
        "id": "rBdaSrgq67sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defination functions\n",
        "def calculate_sales(unit_price, quantity, discount):\n",
        "    return unit_price * quantity * (1 - discount)\n",
        "\n",
        "def calculate_profit(sales):\n",
        "    return sales * 0.15  # % share of sales used as COGS price is not available\n",
        "\n",
        "def calculate_profit_margin(sales, profit):\n",
        "    return (profit / sales) * 100 if sales != 0 else 0\n",
        "\n",
        "def update_month_columns(df):\n",
        "    df['order_date'] = pd.to_datetime(df['order_date'])\n",
        "    df['order_month_name'] = df['order_date'].dt.month_name()\n",
        "    df['order_month_num'] = df['order_date'].dt.month\n",
        "    return df\n",
        "\n",
        "def save_csv(df):\n",
        "    df.to_csv(\"updated_sales_data.csv\", index=False)\n",
        "    print(\"\\nSaved as updated_sales_data.csv\\n\")\n",
        "\n",
        "# menu functions\n",
        "def search_record(df_edit):\n",
        "    print(\"\\n---- Search Customer ----\")\n",
        "    print(\"1. by Order ID\")\n",
        "    print(\"2. by Customer Name (fuzzy)\")\n",
        "    print(\"3. Exit\")\n",
        "\n",
        "    choice = input(\"\\nEnter choice: \")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        try:\n",
        "          order_id = int(input(\"\\nEnter Order ID to search: \").strip())\n",
        "        except ValueError:\n",
        "          print(\"Invalid input! Please enter a numeric Order ID.\\n\")\n",
        "          return df_edit # Return df_edit on invalid input\n",
        "\n",
        "        # check if order exists\n",
        "        if order_id not in df_edit['order_id'].values:\n",
        "            print(\"Order ID not found!\\n\")\n",
        "            return df_edit # Return df_edit if order not found\n",
        "\n",
        "        # get the matching row\n",
        "        row = df_edit[df_edit['order_id'] == order_id]\n",
        "\n",
        "        print(\"\\nRecord Found:\\n\")\n",
        "        print(tabulate(row, headers=\"keys\", tablefmt=\"psql\"))\n",
        "\n",
        "        return df_edit  # returns the full df_edit to maintain state\n",
        "    elif choice == \"2\":\n",
        "        name_input = input(\"\\nEnter customer name to search: \").strip()\n",
        "\n",
        "        customer_names = df_edit['customer_name'].dropna().unique().tolist()\n",
        "\n",
        "        # fuzzy pass\n",
        "        matches = get_close_matches(name_input, customer_names, n=999,\n",
        "        cutoff=0.5)   # lower = more tolerant\n",
        "\n",
        "        if not matches:\n",
        "          print(\"No similar customer names found!\\n\")\n",
        "          return df_edit\n",
        "\n",
        "        # if only one match, use it directly\n",
        "        if len(matches) == 1:\n",
        "          selected_name = matches[0]\n",
        "        else:\n",
        "          # show numbered menu\n",
        "          print(\"\\nMultiple matches found:\")\n",
        "          for i, name in enumerate(matches, start=1):\n",
        "              print(f\"{i}. {name}\")\n",
        "          # let user choose\n",
        "          while True:\n",
        "              choice = input(f\"Select the correct customer (1-{len(matches)}): \").strip()\n",
        "              if choice.isdigit() and 1 <= int(choice) <= len(matches):\n",
        "                  selected_name = matches[int(choice)-1]\n",
        "                  break\n",
        "              print(\"Invalid choice, try again.\")\n",
        "\n",
        "        # filter rows for the selected customer\n",
        "        result = df_edit[df_edit['customer_name'] == selected_name]\n",
        "\n",
        "        print(f\"\\nRecords for customer: {selected_name}\\n\")\n",
        "        print(tabulate(result, headers=\"keys\", tablefmt=\"psql\"))\n",
        "\n",
        "        return df_edit\n",
        "    elif choice == \"3\":\n",
        "        print(\"\\nExiting search...\")\n",
        "        return df_edit\n",
        "    else:\n",
        "        print(\"Invalid choice. Try again.\")\n",
        "        return df_edit # Added to ensure df_edit is always returned\n",
        "\n",
        "# adding rows to dataset\n",
        "def add_new_record(df_edit):\n",
        "    print(\"\\nEnter New Record Details:\")\n",
        "    new_row = {}\n",
        "    new_row['order_id'] = input(\"Order ID: \")\n",
        "    new_row['order_date'] = input(\"Order Date (YYYY-MM-DD): \")\n",
        "    new_row['customer_name'] = input(\"Customer Name: \")\n",
        "    new_row['region'] = input(\"Region: \")\n",
        "    new_row['city'] = input(\"City: \")\n",
        "    new_row['category'] = input(\"Category: \")\n",
        "    new_row['subcategory'] = input(\"Subcategory: \")\n",
        "    new_row['product_name'] = input(\"Product Name: \")\n",
        "    new_row['quantity'] = int(input(\"Quantity: \"))\n",
        "    new_row['unit_price'] = float(input(\"Unit Price: \"))\n",
        "    new_row['discount'] = float(input(\"Discount (0-1): \"))\n",
        "\n",
        "    new_row['sales'] = calculate_sales(new_row['unit_price'], new_row['quantity'], new_row['discount'])\n",
        "    new_row['profit'] = calculate_profit(new_row['sales'])\n",
        "    new_row['payment_mode'] = input(\"Payment Mode: \")\n",
        "    new_row['profit_margin'] = calculate_profit_margin(new_row['sales'], new_row['profit'])\n",
        "\n",
        "    df_edit.loc[len(df_edit)] = new_row\n",
        "    df_edit = update_month_columns(df_edit)\n",
        "    save_csv(df_edit)\n",
        "\n",
        "    print(\"\\nRecord Added Successfully! New rows:\\n\")\n",
        "    print(tabulate(df_edit.tail(5), headers=\"keys\", tablefmt=\"psql\"))\n",
        "    return df_edit\n",
        "\n",
        "# modifying rows to dataset\n",
        "def modify_record(df_edit):\n",
        "    order_id = input(\"\\nEnter Order ID to modify: \")\n",
        "    # Convert order_id to the correct type for comparison if it's stored as int in df_edit\n",
        "    # Assuming order_id is stored as int for now, or it will be converted in input\n",
        "    try:\n",
        "        order_id = int(order_id)\n",
        "    except ValueError:\n",
        "        print(\"Invalid Order ID format. Please enter a number.\\n\")\n",
        "        return df_edit\n",
        "\n",
        "    if order_id not in df_edit['order_id'].values:\n",
        "        print(\"Order ID not found!\\n\")\n",
        "        return df_edit\n",
        "\n",
        "    row_index = df_edit[df_edit['order_id'] == order_id].index[0]\n",
        "\n",
        "    print(\"\\nColumns you can modify:\")\n",
        "    print(df_edit.columns.tolist())\n",
        "    col = input(\"Column name to modify: \")\n",
        "\n",
        "    if col not in df_edit.columns:\n",
        "        print(\"Invalid column!\\n\")\n",
        "        return df_edit\n",
        "\n",
        "    new_value = input(\"Enter new value: \")\n",
        "\n",
        "    # Convert numeric fields\n",
        "    if col in ['quantity', 'order_month_num']:\n",
        "        try:\n",
        "            new_value = int(new_value)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid input for {col}. Please enter an integer.\\n\")\n",
        "            return df_edit\n",
        "    elif col in ['unit_price', 'discount', 'sales', 'profit', 'profit_margin']:\n",
        "        try:\n",
        "            new_value = float(new_value)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid input for {col}. Please enter a number.\\n\")\n",
        "            return df_edit\n",
        "    elif col == 'order_date':\n",
        "        try:\n",
        "            new_value = pd.to_datetime(new_value)\n",
        "        except ValueError:\n",
        "            print(f\"Invalid input for {col}. Please enter date in YYYY-MM-DD format.\\n\")\n",
        "            return df_edit\n",
        "\n",
        "    df_edit.at[row_index, col] = new_value\n",
        "\n",
        "    # Recalculate dependent fields if needed\n",
        "    if col in ['order_date', 'quantity', 'unit_price', 'discount', 'profit']:\n",
        "        r = df_edit.loc[row_index]\n",
        "        df_edit.at[row_index, 'sales'] = calculate_sales(r['unit_price'], r['quantity'], r['discount'])\n",
        "        df_edit.at[row_index, 'profit'] = calculate_profit(df_edit.at[row_index, 'sales']) # Recalculate profit if sales changes\n",
        "        df_edit.at[row_index, 'profit_margin'] = calculate_profit_margin(df_edit.at[row_index, 'sales'], df_edit.at[row_index, 'profit'])\n",
        "        df_edit = update_month_columns(df_edit)\n",
        "\n",
        "    save_csv(df_edit)\n",
        "    print(\"\\nRecord Modified! Updated row:\\n\")\n",
        "    print(tabulate(df_edit.loc[[row_index]], headers=\"keys\", tablefmt=\"psql\"))\n",
        "    return df_edit\n",
        "\n",
        "# deletion of rows from dataset\n",
        "def delete_record(df_edit):\n",
        "    order_id = input(\"\\nEnter Order ID to delete: \")\n",
        "    try:\n",
        "        order_id = int(order_id)\n",
        "    except ValueError:\n",
        "        print(\"Invalid Order ID format. Please enter a number.\\n\")\n",
        "        return df_edit\n",
        "\n",
        "    if order_id not in df_edit['order_id'].values:\n",
        "        print(\"Order ID not found!\\n\")\n",
        "        return df_edit\n",
        "\n",
        "    df_edit = df_edit[df_edit['order_id'] != order_id].reset_index(drop=True)\n",
        "    save_csv(df_edit)\n",
        "    print(\"\\nRecord Deleted! Latest rows:\\n\")\n",
        "    print(tabulate(df_edit.tail(5), headers=\"keys\", tablefmt=\"psql\"))\n",
        "    return df_edit\n",
        "\n",
        "# satistical function explorer\n",
        "def statisics_record(df_edit):\n",
        "    print(\"\\n---- Statistical Analysis ----\")\n",
        "    print(\"1. Sales by Year\")\n",
        "    print(\"2. Profit Margin by Year\")\n",
        "    print(\"3. Sales by Month\")\n",
        "    print(\"4. Top City Sales\")\n",
        "    print(\"5. Exit\")\n",
        "    choice = input(\"\\nEnter choice: \")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        plot_sales_by_year(df_edit)\n",
        "        return df_edit\n",
        "    elif choice == \"2\":\n",
        "        plot_profit_margin_by_year(df_edit)\n",
        "        return df_edit\n",
        "    elif choice == \"3\":\n",
        "        plot_sales_by_month(df_edit)\n",
        "        return df_edit\n",
        "    elif choice == \"4\":\n",
        "\n",
        "        try:\n",
        "            top = int(input(\"Enter the number of top cities to display: \"))\n",
        "        except ValueError:\n",
        "            print(\"Invalid input, using default top 10.\")\n",
        "            top = 10\n",
        "\n",
        "        # fig = plt.gcf() # This line is not needed here as plot_top_cities handles it\n",
        "        plot_top_cities(df_edit, top)\n",
        "        # plt.show() # plot_top_cities already shows the plot\n",
        "        # plt.close(fig) # plot_top_cities already closes the figure\n",
        "        return df_edit\n",
        "    elif choice == \"5\":\n",
        "        print(\"\\nExiting statistical analysis...\")\n",
        "        return df_edit\n",
        "    else:\n",
        "        print(\"Invalid choice. Try again.\")\n",
        "        return df_edit\n",
        "\n",
        "# database showcase\n",
        "def show_dataset(df_edit):\n",
        "    print(\"\\n---- Edited Dataset Preview ----\")\n",
        "    print(tabulate(df_edit.head(10), headers=\"keys\", tablefmt=\"psql\"))\n",
        "\n",
        "# menu editor\n",
        "def menu_based_data_editor(df_clean):\n",
        "    df_edit = df_clean.copy()  # work on copy\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n------------ MENU ------------\")\n",
        "        print(\"1. Add new record\")\n",
        "        print(\"2. Modify a record by Order ID\")\n",
        "        print(\"3. Delete a record by Order ID\")\n",
        "        print(\"4. Show dataset preview\")\n",
        "        print(\"5. Satistics \")\n",
        "        print(\"6. Search Customer\")\n",
        "        print(\"7. Exit\")\n",
        "        choice = input(\"\\nEnter choice: \")\n",
        "\n",
        "        match choice:\n",
        "            case \"1\":\n",
        "                df_edit = add_new_record(df_edit)\n",
        "            case \"2\":\n",
        "                df_edit = modify_record(df_edit)\n",
        "            case \"3\":\n",
        "                df_edit = delete_record(df_edit)\n",
        "            case \"4\":\n",
        "                show_dataset(df_edit)\n",
        "            case \"5\":\n",
        "                df_edit = statisics_record(df_edit)\n",
        "                pass\n",
        "            case \"6\":\n",
        "                df_edit = search_record(df_edit)\n",
        "            case \"7\":\n",
        "                print(\"\\nExiting menu...\")\n",
        "                return df_edit\n",
        "            case _:\n",
        "                print(\"Invalid choice. Try again.\")\n",
        "\n",
        "# menu viewer\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        print(\"Dataset loaded successfully. Total rows:\", len(df_clean))\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found! Please make sure 'sales_data.csv' exists.\")\n",
        "        exit()\n",
        "\n",
        "    df_updated = menu_based_data_editor(df_clean)\n",
        "\n",
        "    print(\"\\nFinal Edited Dataset Preview:\\n\")\n",
        "    print(tabulate(df_updated.tail(10), headers=\"keys\", tablefmt=\"psql\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZYgZfCw7XTN",
        "outputId": "564a01e5-92d5-4ee5-fbef-33203041e8e0",
        "collapsed": true
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded successfully. Total rows: 5000\n",
            "\n",
            "------------ MENU ------------\n",
            "1. Add new record\n",
            "2. Modify a record by Order ID\n",
            "3. Delete a record by Order ID\n",
            "4. Show dataset preview\n",
            "5. Satistics \n",
            "6. Search Customer\n",
            "7. Exit\n",
            "\n",
            "Enter choice: 1\n",
            "\n",
            "Enter New Record Details:\n",
            "Order ID: 15001\n",
            "Order Date (YYYY-MM-DD): 2025-12-09\n",
            "Customer Name: Ayush\n",
            "Region: West\n",
            "City: Pune\n",
            "Category: Books\n",
            "Subcategory: Fiction\n",
            "Product Name: Harry\n",
            "Quantity: 2\n",
            "Unit Price: 750\n",
            "Discount (0-1): 0.2\n",
            "Payment Mode: Credit\n",
            "\n",
            "Saved as updated_sales_data.csv\n",
            "\n",
            "\n",
            "Record Added Successfully! New rows:\n",
            "\n",
            "+------+------------+---------------------+-------------------+----------+-----------+-------------+----------------+---------------------+------------+--------------+------------+----------+----------+----------------+-----------------+--------------------+-------------------+\n",
            "|      |   order_id | order_date          | customer_name     | region   | city      | category    | sub-category   | product_name        |   quantity |   unit_price |   discount |    sales |   profit | payment_mode   |   profit_margin | order_month_name   |   order_month_num |\n",
            "|------+------------+---------------------+-------------------+----------+-----------+-------------+----------------+---------------------+------------+--------------+------------+----------+----------+----------------+-----------------+--------------------+-------------------|\n",
            "| 4996 |      14997 | 2024-12-22 00:00:00 | Aaina Chander     | North    | Jaipur    | Toys        | Doll           | Doll Nulla          |          5 |        70048 |        0   | 350240   | 31237.2  | Credit Card    |         8.91881 | December           |                12 |\n",
            "| 4997 |      14998 | 2025-04-15 00:00:00 | Dhanush Gara      | South    | Bangalore | Beauty      | Lipstick       | Lipstick Eaque      |          1 |        42162 |       15   |  35837.7 |  7827.5  | Debit Card     |        21.8415  | April              |                 4 |\n",
            "| 4998 |      14999 | 2024-07-08 00:00:00 | Divyansh Malhotra | East     | Kolkata   | Electronics | Smartwatch     | Smartwatch Adipisci |          4 |        13568 |       10   |  48844.8 |  6603.86 | Credit Card    |        13.5201  | July               |                 7 |\n",
            "| 4999 |      15000 | 2024-02-04 00:00:00 | Aarush Walla      | West     | Goa       | Clothing    | Kids Wear      | Kids Wear Repellat  |          1 |        76762 |       10   |  69085.8 |  5785.85 | Net Banking    |         8.37488 | February           |                 2 |\n",
            "| 5000 |      15001 | 2025-12-09 00:00:00 | Ayush             | West     | Pune      | Books       | nan            | Harry               |          2 |          750 |        0.2 |   1200   |   180    | Credit         |        15       | December           |                12 |\n",
            "+------+------------+---------------------+-------------------+----------+-----------+-------------+----------------+---------------------+------------+--------------+------------+----------+----------+----------------+-----------------+--------------------+-------------------+\n",
            "\n",
            "------------ MENU ------------\n",
            "1. Add new record\n",
            "2. Modify a record by Order ID\n",
            "3. Delete a record by Order ID\n",
            "4. Show dataset preview\n",
            "5. Satistics \n",
            "6. Search Customer\n",
            "7. Exit\n",
            "\n",
            "Enter choice: 6\n",
            "\n",
            "---- Search Customer ----\n",
            "1. by Order ID\n",
            "2. by Customer Name (fuzzy)\n",
            "3. Exit\n",
            "\n",
            "Enter choice: 1\n",
            "\n",
            "Enter Order ID to search: 15001\n",
            "Order ID not found!\n",
            "\n",
            "\n",
            "------------ MENU ------------\n",
            "1. Add new record\n",
            "2. Modify a record by Order ID\n",
            "3. Delete a record by Order ID\n",
            "4. Show dataset preview\n",
            "5. Satistics \n",
            "6. Search Customer\n",
            "7. Exit\n",
            "\n",
            "Enter choice: 2\n",
            "\n",
            "Enter Order ID to modify: Ayush\n",
            "Invalid Order ID format. Please enter a number.\n",
            "\n",
            "\n",
            "------------ MENU ------------\n",
            "1. Add new record\n",
            "2. Modify a record by Order ID\n",
            "3. Delete a record by Order ID\n",
            "4. Show dataset preview\n",
            "5. Satistics \n",
            "6. Search Customer\n",
            "7. Exit\n",
            "\n",
            "Enter choice: 6\n",
            "\n",
            "---- Search Customer ----\n",
            "1. by Order ID\n",
            "2. by Customer Name (fuzzy)\n",
            "3. Exit\n",
            "\n",
            "Enter choice: 2\n",
            "\n",
            "Enter customer name to search: Ayush\n",
            "\n",
            "Multiple matches found:\n",
            "1. Ayush\n",
            "2. Aayush Tak\n",
            "3. Aayush Sur\n",
            "4. Aayush Toor\n",
            "5. Aayush Sood\n",
            "6. Aayush Gill\n",
            "7. Aayush Dutt\n",
            "8. Aayush Dass\n",
            "9. Aayush Setty\n",
            "10. Aayush Krish\n",
            "11. Aayush Kakar\n",
            "12. Aayush Boase\n",
            "13. Aayush Bassi\n",
            "14. Ayesha Ray\n",
            "15. Ayesha Kar\n",
            "16. Anay Ghosh\n",
            "17. Aarush Vig\n",
            "18. Ayesha Vasa\n",
            "19. Ayesha Sant\n",
            "20. Ayesha Jain\n",
            "21. Ayesha Dani\n",
            "22. Anaya Krish\n",
            "23. Aayush Sengupta\n",
            "24. Aayush Banerjee\n",
            "25. Aarush Raja\n",
            "26. Aarush Mani\n",
            "27. Aarush Mall\n",
            "28. Aarush Kaur\n",
            "29. Aarush Jani\n",
            "30. Aarush Buch\n",
            "31. Aarush Bahl\n",
            "Select the correct customer (1-31): 1\n",
            "\n",
            "Records for customer: Ayush\n",
            "\n",
            "+------+------------+---------------------+-----------------+----------+--------+------------+----------------+----------------+------------+--------------+------------+---------+----------+----------------+-----------------+--------------------+-------------------+\n",
            "|      |   order_id | order_date          | customer_name   | region   | city   | category   |   sub-category | product_name   |   quantity |   unit_price |   discount |   sales |   profit | payment_mode   |   profit_margin | order_month_name   |   order_month_num |\n",
            "|------+------------+---------------------+-----------------+----------+--------+------------+----------------+----------------+------------+--------------+------------+---------+----------+----------------+-----------------+--------------------+-------------------|\n",
            "| 5000 |      15001 | 2025-12-09 00:00:00 | Ayush           | West     | Pune   | Books      |            nan | Harry          |          2 |          750 |        0.2 |    1200 |      180 | Credit         |              15 | December           |                12 |\n",
            "+------+------------+---------------------+-----------------+----------+--------+------------+----------------+----------------+------------+--------------+------------+---------+----------+----------------+-----------------+--------------------+-------------------+\n",
            "\n",
            "------------ MENU ------------\n",
            "1. Add new record\n",
            "2. Modify a record by Order ID\n",
            "3. Delete a record by Order ID\n",
            "4. Show dataset preview\n",
            "5. Satistics \n",
            "6. Search Customer\n",
            "7. Exit\n",
            "\n",
            "Enter choice: 6\n",
            "\n",
            "---- Search Customer ----\n",
            "1. by Order ID\n",
            "2. by Customer Name (fuzzy)\n",
            "3. Exit\n",
            "\n",
            "Enter choice: 1\n",
            "\n",
            "Enter Order ID to search: 15001\n",
            "Order ID not found!\n",
            "\n",
            "\n",
            "------------ MENU ------------\n",
            "1. Add new record\n",
            "2. Modify a record by Order ID\n",
            "3. Delete a record by Order ID\n",
            "4. Show dataset preview\n",
            "5. Satistics \n",
            "6. Search Customer\n",
            "7. Exit\n",
            "\n",
            "Enter choice: 7\n",
            "\n",
            "Exiting menu...\n",
            "\n",
            "Final Edited Dataset Preview:\n",
            "\n",
            "+------+------------+---------------------+-------------------+----------+-----------+-------------+----------------+---------------------+------------+--------------+------------+----------+----------+----------------+-----------------+--------------------+-------------------+\n",
            "|      |   order_id | order_date          | customer_name     | region   | city      | category    | sub-category   | product_name        |   quantity |   unit_price |   discount |    sales |   profit | payment_mode   |   profit_margin | order_month_name   |   order_month_num |\n",
            "|------+------------+---------------------+-------------------+----------+-----------+-------------+----------------+---------------------+------------+--------------+------------+----------+----------+----------------+-----------------+--------------------+-------------------|\n",
            "| 4991 |      14992 | 2024-09-06 00:00:00 | Alisha Malhotra   | West     | Mumbai    | Beauty      | Shampoo        | Shampoo Magni       |          3 |         4930 |       15   |  12571.5 |  1698.86 | Net Banking    |        13.5136  | September          |                 9 |\n",
            "| 4992 |      14993 | 2025-08-18 00:00:00 | Bhamini Sarin     | North    | Delhi     | Groceries   | Rice           | Rice Neque          |          3 |        14477 |       10   |  39087.9 |  2939.6  | Credit Card    |         7.52049 | August             |                 8 |\n",
            "| 4993 |      14994 | 2025-03-22 00:00:00 | Kavya Lalla       | South    | Chennai   | Furniture   | Sofa           | Sofa Minus          |          3 |          673 |        0   |   2019   |   148.32 | Credit Card    |         7.34621 | March              |                 3 |\n",
            "| 4994 |      14995 | 2025-01-06 00:00:00 | Hunar Vaidya      | North    | Amritsar  | Sports      | Tennis Racket  | Tennis Racket Omnis |          1 |        72936 |       15   |  61995.6 |  5224.04 | Cod            |         8.42647 | January            |                 1 |\n",
            "| 4995 |      14996 | 2024-06-25 00:00:00 | Nishith Kulkarni  | East     | Kolkata   | Books       | Fiction        | Fiction Veritatis   |          3 |        60671 |        0   | 182013   | 11853.1  | Debit Card     |         6.51225 | June               |                 6 |\n",
            "| 4996 |      14997 | 2024-12-22 00:00:00 | Aaina Chander     | North    | Jaipur    | Toys        | Doll           | Doll Nulla          |          5 |        70048 |        0   | 350240   | 31237.2  | Credit Card    |         8.91881 | December           |                12 |\n",
            "| 4997 |      14998 | 2025-04-15 00:00:00 | Dhanush Gara      | South    | Bangalore | Beauty      | Lipstick       | Lipstick Eaque      |          1 |        42162 |       15   |  35837.7 |  7827.5  | Debit Card     |        21.8415  | April              |                 4 |\n",
            "| 4998 |      14999 | 2024-07-08 00:00:00 | Divyansh Malhotra | East     | Kolkata   | Electronics | Smartwatch     | Smartwatch Adipisci |          4 |        13568 |       10   |  48844.8 |  6603.86 | Credit Card    |        13.5201  | July               |                 7 |\n",
            "| 4999 |      15000 | 2024-02-04 00:00:00 | Aarush Walla      | West     | Goa       | Clothing    | Kids Wear      | Kids Wear Repellat  |          1 |        76762 |       10   |  69085.8 |  5785.85 | Net Banking    |         8.37488 | February           |                 2 |\n",
            "| 5000 |      15001 | 2025-12-09 00:00:00 | Ayush             | West     | Pune      | Books       | nan            | Harry               |          2 |          750 |        0.2 |   1200   |   180    | Credit         |        15       | December           |                12 |\n",
            "+------+------------+---------------------+-------------------+----------+-----------+-------------+----------------+---------------------+------------+--------------+------------+----------+----------+----------------+-----------------+--------------------+-------------------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}